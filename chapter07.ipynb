{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7章：質問応答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['books', 'electronics', 'grocery', 'movies', 'restaurants', 'tripadvisor']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names, load_dataset\n",
    "\n",
    "domains = get_dataset_config_names(\"subjqa\")\n",
    "domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset subjqa (/home/ace14385kw/.cache/huggingface/datasets/subjqa/electronics/1.1.0/e5588f9298ff2d70686a00cc377e4bdccf4e32287459e3c6baf2dc5ab57fe7fd)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ab35401c474e19aad2254962f33db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'text': ['Bass is weak as expected',\n",
       "  'Bass is weak as expected, even with EQ adjusted up'],\n",
       " 'answer_start': [1302, 1302],\n",
       " 'answer_subj_level': [1, 1],\n",
       " 'ans_subj_score': [0.5083333253860474, 0.5083333253860474],\n",
       " 'is_ans_subjective': [True, True]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjqa = load_dataset(\"subjqa\", name=\"electronics\")\n",
    "subjqa[\"train\"][\"answers\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions in train: 1295\n",
      "Number of questions in test: 358\n",
      "Number of questions in validation: 255\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = {split: dset.to_pandas() for split, dset in subjqa.flatten().items()}\n",
    "\n",
    "for split, df in dfs.items():\n",
    "    print(f\"Number of questions in {split}: {df['id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>answers.text</th>\n",
       "      <th>answers.answer_start</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>B005DKZTMG</td>\n",
       "      <td>Does the keyboard lightweight?</td>\n",
       "      <td>[this keyboard is compact]</td>\n",
       "      <td>[215]</td>\n",
       "      <td>I really like this keyboard.  I give it 4 star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>B00AAIPT76</td>\n",
       "      <td>How is the battery?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>I bought this after the first spare gopro batt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title                        question                answers.text  \\\n",
       "791   B005DKZTMG  Does the keyboard lightweight?  [this keyboard is compact]   \n",
       "1159  B00AAIPT76             How is the battery?                          []   \n",
       "\n",
       "     answers.answer_start                                            context  \n",
       "791                 [215]  I really like this keyboard.  I give it 4 star...  \n",
       "1159                   []  I bought this after the first spare gopro batt...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampleでランダムな行をサンプリング\n",
    "qa_cols = [\"title\", \"question\", \"answers.text\", \"answers.answer_start\", \"context\"]\n",
    "sample_df = dfs[\"train\"][qa_cols].sample(2, random_state=7)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts = {}\n",
    "question_types = [\"What\", \"How\", \"Is\", \"Does\", \"Do\", \"Was\", \"Where\", \"Why\"]\n",
    "\n",
    "for q in question_types:\n",
    "    counts[q] = dfs[\"train\"][\"question\"].str.startswith(q).value_counts()[True]\n",
    "\n",
    "pd.Series(counts).sort_values().plot.barh()\n",
    "plt.title(\"Frequency of Question Types\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinuLMによるQAシステムの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[  101,  2129,  2172,  2189,  2064,  2023,  2907,  1029,   102,  2019,\n",
       "          23378,  2003,  2055,  1015, 16914,  1013,  3371,  1010,  2061,  2055,\n",
       "          25961,  2847,  5834,  2006,  5371,  2946,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1]])},\n",
       " '[CLS] how much music can this hold? [SEP] an mp3 is about 1 mb / minute, so about 6000 hours depending on file size. [SEP]')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepset/minilm-uncased-squad2\")\n",
    "question = \"How much music can this hold?\"\n",
    "context = \"An MP3 is about 1 MB/minute, so about 6000 hours depending on file size.\"\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "inputs, tokenizer.decode(inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-0.9862, -4.7750, -5.4025, -5.2378, -5.2863, -5.5117, -4.9819, -6.1880,\n",
       "         -0.9862,  0.2596, -0.2144, -1.7136,  3.7806,  4.8561, -1.0546, -3.9097,\n",
       "         -1.7374, -4.5944, -1.4278,  3.9949,  5.0391, -0.2018, -3.0193, -4.8549,\n",
       "         -2.3107, -3.5110, -3.5713, -0.9862]]), end_logits=tensor([[-0.9623, -5.4733, -5.0326, -5.1639, -5.4278, -5.5151, -5.1749, -4.6233,\n",
       "         -0.9623, -3.7855, -0.8715, -3.7745, -3.0161, -1.1780,  0.1758, -2.7365,\n",
       "          4.8934,  0.3046, -3.1761, -3.2762,  0.8937,  5.6606, -0.3623, -4.9554,\n",
       "         -3.2531, -0.0914,  1.6211, -0.9623]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/minilm-uncased-squad2\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "outputs # QA向けの出力形式であることが確認できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6000 hours'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "\n",
    "start_idx = torch.argmax(start_logits)\n",
    "end_idx = torch.argmax(end_logits) + 1\n",
    "answer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\n",
    "answer = tokenizer.decode(answer_span)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ace14385kw/anaconda3/lib/python3.9/site-packages/transformers/pipelines/question_answering.py:189: UserWarning: topk parameter is deprecated, use top_k instead\n",
      "  warnings.warn(\"topk parameter is deprecated, use top_k instead\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.2651613652706146, 'start': 38, 'end': 48, 'answer': '6000 hours'},\n",
       " {'score': 0.2208300232887268,\n",
       "  'start': 16,\n",
       "  'end': 48,\n",
       "  'answer': '1 MB/minute, so about 6000 hours'},\n",
       " {'score': 0.1025354415178299,\n",
       "  'start': 16,\n",
       "  'end': 27,\n",
       "  'answer': '1 MB/minute'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "pipe(question=question, context=context, topk=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window #0 has 100 tokens\n",
      "Window #1 has 88 tokens\n"
     ]
    }
   ],
   "source": [
    "# スライディングウィンドウ戦略による長い入力への対処\n",
    "example = dfs[\"train\"].iloc[0][[\"question\", \"context\"]]\n",
    "tokenized_example = tokenizer(example[\"question\"], example[\"context\"], return_overflowing_tokens=True, max_length=100, stride=25)\n",
    "\n",
    "for idx, window in enumerate(tokenized_example[\"input_ids\"]):\n",
    "    print(f\"Window #{idx} has {len(window)} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haystackを用いたQAパイプラインの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "url = \"\"\"https://artifacts.elastic.co/downloads/elasticsearch/\\\n",
    "elasticsearch-7.9.2-linux-x86_64.tar.gz\"\"\"\n",
    "!wget -nc -q {url}\n",
    "!tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elasticsearchの起動\n",
    "import os\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "\n",
    "!chown -R daemon:daemon elasticsearch-7.9.2\n",
    "es_server = Popen(args=['elasticsearch-7.9.2/bin/elasticsearch'], stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1))\n",
    "!sleep 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(return_embedding=True)\n",
    "\n",
    "for split, df in dfs.items():\n",
    "    # 重複レビューの除去\n",
    "    docs = [{\"text\": row[\"context\"],\n",
    "            \"meta\":{\"item_id\": row[\"title\"], \"question_id\": row[\"id\"], \"split\": split}}\n",
    "        for _, row in df.drop_duplicates(subset=\"context\").iterrows()]\n",
    "    document_store.write_documents(docs, index=\"document\")\n",
    "\n",
    "document_store.get_document_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'document_store' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27381/1793971589.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhaystack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElasticsearchRetriever\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mes_retriever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElasticsearchRetriever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_store\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocument_store\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'document_store' is not defined"
     ]
    }
   ],
   "source": [
    "from haystack.retriever.sparse import ElasticsearchRetriever\n",
    "\n",
    "es_retriever = ElasticsearchRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.reader.farm import FARMReader\n",
    "\n",
    "max_seq_length, doc_stride = 384, 128\n",
    "reader = FARMReader(model_name_or_path=\"deepset/minilm-uncased-squad2\", progress_bar=False, max_seq_len=max_seq_length, doc_stride=doc_stride, return_no_answer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パイプラインによるコンポーネントの組み合わせ\n",
    "from haystack.pipeline import ExtractiveQAPipeline\n",
    "\n",
    "pipe = ExtractiveQAPipeline(reader, es_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = \"B0074BW614\"\n",
    "query = \"Is it good for reading?\"\n",
    "preds = pipe.run(query=query, top_k_retriever=3, top_k_reader=3, filters={\"item_id\": [item_id], \"split\": [\"train\"]})\n",
    "\n",
    "print(f\"Question: {preds['query']} \\n\")\n",
    "for idx in range(3):\n",
    "    print(f\"Answer {idx+1}: {preds['answers'][idx]['answer']}\")\n",
    "    print(f\"Review snippet: ...{preds['answers'][idx]['context']}...\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QAパイプラインの改善"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineNode:\n",
    "    def __init__(self):\n",
    "        self.outgoing_edges = 1\n",
    "    \n",
    "    def run(self, **kwargs):\n",
    "        ...\n",
    "        return (outputs, \"outgoing_edge_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever評価ノードの作成\n",
    "from haystack.pipeline import Pipeline\n",
    "from haystack.eval import EvalDocuments\n",
    "\n",
    "class EvalRetrieverPipeline:\n",
    "    def __init__(self, retriever):\n",
    "        self.retriever = retriever\n",
    "        self.eval_retriever = EvalDocuments()\n",
    "        pipe = Pipeline()\n",
    "        pipe.add_node(component=self.retriever, name=\"ESRetriever\", inputs=[\"Query\"])\n",
    "        pipe.add_node(component=self.eval_retriever, name=\"EvalRetriever\", inputs=[\"ESRetriever\"]) # 直前のノード名をinputsに指定\n",
    "        self.pipeline = pipe\n",
    "\n",
    "pipe = EvalRetrieverPipeline(es_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Label\n",
    "\n",
    "labels = []\n",
    "for i, row in dfs[\"test\"].iterrows():\n",
    "    # Retrieverのフィルタリングに使うメタデータ\n",
    "    meta = {\"item_id\": row[\"title\"], \"question_id\": row[\"id\"]}\n",
    "    # 回答のある質問のラベルを追加\n",
    "    if len(row[\"answers.text\"]):\n",
    "        for answer in row[\"answers.text\"]:\n",
    "            label = Label(\n",
    "                question=row[\"question\"], answer=answer, id=i, origin=row[\"id\"],\n",
    "                meta=meta, is_correct_answer=True, is_correct_document=True,\n",
    "                no_answer=False)\n",
    "            labels.append(label)\n",
    "    # 回答のない質問のラベルを追加\n",
    "    else:\n",
    "        label = Label(\n",
    "            question=row[\"question\"], answer=\"\", id=i, origin=row[\"id\"],\n",
    "            meta=meta, is_correct_answer=True, is_correct_document=True,\n",
    "            no_answer=True)  \n",
    "        labels.append(label)\n",
    "\n",
    "# Elasticsearchに書き込み\n",
    "document_store.write_labels(labels, index=\"label\")\n",
    "\n",
    "# 一意なIDに関連するすべての質問-回答のペアを集約\n",
    "labels_agg = document_store.get_all_labels_aggregated(index=\"label\", open_domain=True, aggregate_by_meta=[\"item_id\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(pipeline, top_k_retriever=10, top_k_reader=4):\n",
    "    for l in labels_agg:\n",
    "        _ = pipeline.pipeline.run(\n",
    "            query=l.question,\n",
    "            top_k_retriever=top_k_retriever,\n",
    "            top_k_reader=top_k_reader,\n",
    "            top_k_eval_documents=top_k_retriever,    \n",
    "            labels=l,\n",
    "            filters={\"item_id\": [l.meta[\"item_id\"]], \"split\": [\"test\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価と描画\n",
    "def evaluate_retriever(retriever, topk_values = [1,3,5,10,20]):\n",
    "    topk_results = {}\n",
    "\n",
    "    for topk in topk_values:\n",
    "        # Create Pipeline\n",
    "        p = EvalRetrieverPipeline(retriever)\n",
    "        # Loop over each question-answers pair in test set\n",
    "        run_pipeline(p, top_k_retriever=topk)\n",
    "        # Get metrics\n",
    "        topk_results[topk] = {\"recall\": p.eval_retriever.recall}\n",
    "        \n",
    "    return pd.DataFrame.from_dict(topk_results, orient=\"index\")\n",
    "\n",
    "def plot_retriever_eval(dfs, retriever_names):\n",
    "    fig, ax = plt.subplots()\n",
    "    for df, retriever_name in zip(dfs, retriever_names):\n",
    "        df.plot(y=\"recall\", ax=ax, label=retriever_name)\n",
    "    plt.xticks(df.index)\n",
    "    plt.ylabel(\"Top-k Recall\")\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.show()\n",
    "\n",
    "es_topk_df = evaluate_retriever(es_retriever)\n",
    "plot_retriever_eval([es_topk_df], [\"BM25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # DPRの使用\n",
    "from haystack.retriever.dense import DensePassagaRetriever\n",
    "\n",
    "dpr_retriever = DensePassagaRetriever(document_store=document_store,\n",
    "    query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "    passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\", embed_title=False)\n",
    "\n",
    "# 埋め込み表現の更新\n",
    "document_store.update_embeddings(retriever=dpr_retriever)\n",
    "\n",
    "# 評価と描画\n",
    "dpr_topk_df = evaluate_retriever(dpr_retriever)\n",
    "plot_retriever_eval([es_topk_df, dpr_topk_df], [\"BM25\", \"DPR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Readerの評価\n",
    "from farm.evaluation.squad_evaluation import compute_f1, compute_exact\n",
    "\n",
    "pred = \"about 6000 hours\"\n",
    "label = \"6000 hours\"\n",
    "compute_exact(label, pred), compute_f1(label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.eval import EvalAnswers\n",
    "\n",
    "def evaluate_reader(reader):\n",
    "    score_keys = [\"top_1_em\", \"top_1_f1\"]\n",
    "    eval_reader = EvalAnswers(skip_incorrect_retrieval=False)\n",
    "    pipe = Pipeline()\n",
    "    pipe.add_node(component=reader, name=\"QAReader\", inputs=[\"Query\"])\n",
    "    pipe.add_node(component=eval_reader, name=\"EvalReader\", inputs=[\"QAReader\"])\n",
    "\n",
    "    for l in labels_agg:\n",
    "        doc = document_store.query(l.question, \n",
    "                                   filters={\"question_id\":[l.origin]})\n",
    "        _ = pipe.run(query=l.question, documents=doc, labels=l)\n",
    "                \n",
    "    return {k:v for k,v in eval_reader.__dict__.items() if k in score_keys}\n",
    "\n",
    "reader_eval = {}\n",
    "reader_eval[\"Fine-tune on SQuAD\"] = evaluate_reader(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reader_eval(reader_eval):\n",
    "    fig, ax = plt.subplots()\n",
    "    df = pd.DataFrame.from_dict(reader_eval)\n",
    "    df.plot(kind=\"bar\", ylabel=\"Score\", rot=0, ax=ax)\n",
    "    ax.set_xticklabels([\"EM\", \"F1\"])\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "plot_reader_eval(reader_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paragraphs(df):\n",
    "    paragraphs = []\n",
    "    id2context = dict(zip(df[\"review_id\"], df[\"context\"]))\n",
    "    for review_id, review in id2context.items():\n",
    "        qas = []\n",
    "        # Filter for all question-answer pairs about a specific context\n",
    "        review_df = df.query(f\"review_id == '{review_id}'\")\n",
    "        id2question = dict(zip(review_df[\"id\"], review_df[\"question\"]))\n",
    "        # Build up the qas array\n",
    "        for qid, question in id2question.items():\n",
    "            # Filter for a single question ID\n",
    "            question_df = df.query(f\"id == '{qid}'\").to_dict(orient=\"list\")\n",
    "            ans_start_idxs = question_df[\"answers.answer_start\"][0].tolist()\n",
    "            ans_text = question_df[\"answers.text\"][0].tolist()\n",
    "            # Fill answerable questions\n",
    "            if len(ans_start_idxs):\n",
    "                answers = [\n",
    "                    {\"text\": text, \"answer_start\": answer_start}\n",
    "                    for text, answer_start in zip(ans_text, ans_start_idxs)]\n",
    "                is_impossible = False\n",
    "            else:\n",
    "                answers = []\n",
    "                is_impossible = True\n",
    "            # Add question-answer pairs to qas\n",
    "            qas.append({\"question\": question, \"id\": qid, \n",
    "                        \"is_impossible\": is_impossible, \"answers\": answers})\n",
    "        # Add context and question-answer pairs to paragraphs\n",
    "        paragraphs.append({\"qas\": qas, \"context\": review})\n",
    "    return paragraphs\n",
    "\n",
    "product = dfs[\"train\"].query(\"title == 'B00001P4ZH'\")\n",
    "create_paragraphs(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def convert_to_squad(dfs):\n",
    "    for split, df in dfs.items():\n",
    "        subjqa_data = {}\n",
    "        # Create `paragraphs` for each product ID\n",
    "        groups = (df.groupby(\"title\").apply(create_paragraphs)\n",
    "            .to_frame(name=\"paragraphs\").reset_index())\n",
    "        subjqa_data[\"data\"] = groups.to_dict(orient=\"records\")\n",
    "        # Save the result to disk\n",
    "        with open(f\"electronics-{split}.json\", \"w+\", encoding=\"utf-8\") as f:\n",
    "            json.dump(subjqa_data, f)\n",
    "            \n",
    "convert_to_squad(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = \"electronics-train.json\"\n",
    "dev_filename = \"electronics-validation.json\"\n",
    "\n",
    "reader.train(data_dir=\".\", use_gpu=True, n_epochs=1, batch_size=16,\n",
    "             train_filename=train_filename, dev_filename=dev_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_eval[\"Fine-tune on SQuAD + SubjQA\"] = evaluate_reader(reader)\n",
    "plot_reader_eval(reader_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minilm_ckpt = \"microsoft/MiniLM-L12-H384-uncased\"\n",
    "minilm_reader = FARMReader(model_name_or_path=minilm_ckpt, progress_bar=False,\n",
    "                           max_seq_len=max_seq_length, doc_stride=doc_stride,\n",
    "                           return_no_answer=True)\n",
    "\n",
    "minilm_reader.train(data_dir=\".\", use_gpu=True, n_epochs=1, batch_size=16,\n",
    "             train_filename=train_filename, dev_filename=dev_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_eval[\"Fine-tune on SubjQA\"] = evaluate_reader(minilm_reader)\n",
    "plot_reader_eval(reader_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QAパイプライン全体の評価\n",
    "# Initialize retriever pipeline\n",
    "pipe = EvalRetrieverPipeline(es_retriever)\n",
    "# Add nodes for reader\n",
    "eval_reader = EvalAnswers()\n",
    "pipe.pipeline.add_node(component=reader, name=\"QAReader\", \n",
    "              inputs=[\"EvalRetriever\"])\n",
    "pipe.pipeline.add_node(component=eval_reader, name=\"EvalReader\", \n",
    "              inputs=[\"QAReader\"])\n",
    "# Evaluate!\n",
    "run_pipeline(pipe)\n",
    "# Extract metrics from reader\n",
    "reader_eval[\"QA Pipeline (top-1)\"] = {\n",
    "    k:v for k,v in eval_reader.__dict__.items()\n",
    "    if k in [\"top_1_em\", \"top_1_f1\"]}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "606baee2f6c6a883ae4e7978cf8ff1aacbfdacdcde4cfb029f60943c1368433c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
